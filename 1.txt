#include <iostream>
#include <fstream>
#include <cctype>
#include <string>
#include <unordered_map>
#include <vector>
#include <algorithm>
using namespace std;

enum TokenType {
    IDENFR, INTCON, CHARCON, STRCON,
    CONSTTK, INTTK, CHARTK, VOIDTK, MAINTK,
    IFTK, ELSETK, SWITCHTK, CASETK, DEFAULTTK,
    WHILETK, FORTK, SCANFTK, PRINTFTK, RETURNTK,
    PLUS, MINU, MULT, DIV, LSS, LEQ, GRE, GEQ, EQL, NEQ,
    ASSIGN, SEMICN, COMMA, LPARENT, RPARENT,
    LBRACK, RBRACK, LBRACE, RBRACE, COLON
};

struct Token {
    TokenType type;
    string text;
    int line;
};

unordered_map<string, TokenType> keywords = {
    {"const", CONSTTK}, {"int", INTTK}, {"char", CHARTK}, {"void", VOIDTK}, {"main", MAINTK},
    {"if", IFTK}, {"else", ELSETK}, {"switch", SWITCHTK}, {"case", CASETK}, {"default", DEFAULTTK},
    {"while", WHILETK}, {"for", FORTK}, {"scanf", SCANFTK}, {"printf", PRINTFTK}, {"return", RETURNTK}
};

unordered_map<TokenType, string> tokenToString = {
    {IDENFR, "IDENFR"}, {INTCON, "INTCON"}, {CHARCON, "CHARCON"}, {STRCON, "STRCON"},
    {CONSTTK, "CONSTTK"}, {INTTK, "INTTK"}, {CHARTK, "CHARTK"}, {VOIDTK, "VOIDTK"}, {MAINTK, "MAINTK"},
    {IFTK, "IFTK"}, {ELSETK, "ELSETK"}, {SWITCHTK, "SWITCHTK"}, {CASETK, "CASETK"}, {DEFAULTTK, "DEFAULTTK"},
    {WHILETK, "WHILETK"}, {FORTK, "FORTK"}, {SCANFTK, "SCANFTK"}, {PRINTFTK, "PRINTFTK"}, {RETURNTK, "RETURNTK"},
    {PLUS, "PLUS"}, {MINU, "MINU"}, {MULT, "MULT"}, {DIV, "DIV"},
    {LSS, "LSS"}, {LEQ, "LEQ"}, {GRE, "GRE"}, {GEQ, "GEQ"}, {EQL, "EQL"}, {NEQ, "NEQ"},
    {ASSIGN, "ASSIGN"}, {SEMICN, "SEMICN"}, {COMMA, "COMMA"},
    {LPARENT, "LPARENT"}, {RPARENT, "RPARENT"}, {LBRACK, "LBRACK"}, {RBRACK, "RBRACK"},
    {LBRACE, "LBRACE"}, {RBRACE, "RBRACE"}, {COLON, "COLON"}
};

vector<Token> tokens;
ifstream in;
ofstream out;
int line = 1;
char ch;

void nextChar() {
    in.get(ch);
    if (in.eof()) ch = '\0';
    else if (ch == '\n') line++;
}

void addToken(TokenType type, const string& text) {
    tokens.push_back({type, text, line});
}

string toLower(const string& s) {
    string r = s;
    transform(r.begin(), r.end(), r.begin(), ::tolower);
    return r;
}

void lexical() {
    while (in.peek() != EOF) {
        nextChar();
        if (ch == ' ' || ch == '\t' || ch == '\n' || ch == '\r') continue;
        if (ch == '\0') break;

        if (isalpha(ch) || ch == '_') {
            string id;
            do {
                id += ch;
                nextChar();
            } while (isalnum(ch) || ch == '_');
            in.putback(ch);
            string lowerId = toLower(id);
            if (keywords.count(lowerId)) addToken(keywords[lowerId], id);
            else addToken(IDENFR, id);
        }
        else if (isdigit(ch)) {
            string num;
            do {
                num += ch;
                nextChar();
            } while (isdigit(ch));
            in.putback(ch);
            addToken(INTCON, num);
        }
        else if (ch == '\'') {
            string charcon;
            nextChar();
            if (ch == '\\') {
                charcon += ch;
                nextChar();
                charcon += ch;
            } else {
                charcon += ch;
            }
            nextChar();
            addToken(CHARCON, charcon);
        }
        else if (ch == '\"') {
            string strcon;
            nextChar();
            while (ch != '\"') {
                if (ch == '\\') {
                    strcon += ch;
                    nextChar();
                    strcon += ch;
                    nextChar();
                } else {
                    strcon += ch;
                    nextChar();
                }
            }
            addToken(STRCON, strcon);
        }
        else if (ch == '+') addToken(PLUS, "+");
        else if (ch == '-') addToken(MINU, "-");
        else if (ch == '*') addToken(MULT, "*");
        else if (ch == '/') addToken(DIV, "/");
        else if (ch == '<') {
            nextChar();
            if (ch == '=') addToken(LEQ, "<=");
            else { in.putback(ch); addToken(LSS, "<"); }
        }
        else if (ch == '>') {
            nextChar();
            if (ch == '=') addToken(GEQ, ">=");
            else { in.putback(ch); addToken(GRE, ">"); }
        }
        else if (ch == '=') {
            nextChar();
            if (ch == '=') addToken(EQL, "==");
            else { in.putback(ch); addToken(ASSIGN, "="); }
        }
        else if (ch == '!') {
            nextChar();
            if (ch == '=') addToken(NEQ, "!=");
        }
        else if (ch == ';') addToken(SEMICN, ";");
        else if (ch == ',') addToken(COMMA, ",");
        else if (ch == '(') addToken(LPARENT, "(");
        else if (ch == ')') addToken(RPARENT, ")");
        else if (ch == '[') addToken(LBRACK, "[");
        else if (ch == ']') addToken(RBRACK, "]");
        else if (ch == '{') addToken(LBRACE, "{");
        else if (ch == '}') addToken(RBRACE, "}");
        else if (ch == ':') addToken(COLON, ":");
    }
}

string tokenTypeToString(TokenType type) {
    auto it = tokenToString.find(type);
    if (it != tokenToString.end()) return it->second;
    return "UNKNOWN";
}

int main() {
    in.open("testfile.txt");
    out.open("output.txt");
    lexical();
    for (const auto& token : tokens) {
        out << tokenTypeToString(token.type) << " " << token.text << "\n";
    }
    in.close();
    out.close();
    return 0;
}